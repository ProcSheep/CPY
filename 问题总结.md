# 问题总结

- ==部分零散的知识会记录在这里==

## try-catch

- 普通的错误获取：

  ```js
    // 错误的上抛出
    // 在嵌套try-catch中十分重要，如下，三层调用关系（底层 → 中间层 → 上层），每层都可能抛出错误，如果没有cause: error，中间每一次捕获错误后，继续上抛错误都会重新new Error一个新的错误信息，而原始错误数据会丢失，所以经过层级覆盖后，底层操作的错误会被覆盖，最终追溯错误只能到上层业务的函数层级
    // 1. 底层函数（原始错误发生地）
    function底层操作() {
      throw new Error("数据库连接失败"); // 根因错误
    }

    // 2. 中间层函数（处理底层结果）
    function中间处理() {
      try {
        底层操作();
      } catch (err) {
        // 无 cause：仅抛出新错误，原始错误被丢弃
        throw new Error("数据处理失败");
      }
    }

    // 3. 上层业务函数（调用中间层）
    function上层业务() {
      try {
        中间处理();
      } catch (err) {
        // 无 cause：再次抛出新错误，中间层错误被丢弃
        throw new Error("业务执行失败");
      }
    }

    // 最终调用
    try {
      上层业务();
    } catch (err) {
      console.log(err.message); // 只能看到 "业务执行失败"
      console.log(err.stack);   // 堆栈仅显示上层业务的错误位置
      // 完全无法知道底层的 "数据库连接失败" 根因
    }
  ```

- 2.深层错误处理

  ```js
  // 二、核心好处
  // 保留完整错误链路避免原始错误信息丢失。例如，业务层错误（“订单创建失败”）可能由底层错误（“数据库连接失败”）导致，通过 cause 可以追溯到根因，方便调试。
  // 区分错误责任边界上层代码可以专注于处理业务逻辑错误，同时通过 cause 向下传递底层技术错误（如网络、数据库错误），明确错误发生的层次。
  // 简化错误日志与监控日志系统可以通过遍历 cause 链，记录完整的错误堆栈，快速定位问题（例如：前端报错 → 后端接口错误 → 数据库查询错误）。
  // 底层函数：模拟数据库操作
  function queryDB() {
    throw new Error("SQL语法错误"); // 原始错误
  }

  // 中间层：处理数据逻辑
  function processData() {
    try {
      queryDB();
      // throw new Error('processData内业务代码出错了')
    } catch (dbErr) {
      // 包装为数据处理错误，附加原始数据库错误
      // 来自底层的原始错误不会被覆盖（无论层级） 而且本层级正常报错
      throw new Error("数据解析失败", { cause: dbErr });
    }
  }

  // 上层：业务逻辑
  try {
    processData();
    throw new Error("上层内业务代码出错了");
  } catch (bizErr) {
    // 接受非顶层业务的报错
    if (bizErr.cause) {
      console.error("业务错误:", bizErr.message); // 数据解析失败
      console.error("技术根因:", bizErr.cause.message); // SQL语法错误
      console.error("原始错误堆栈:", bizErr.cause.stack); // 可查看底层错误的堆栈信息
    } else {
      // 接受顶层业务的报错
      console.log("顶层业务报错", bizErr);
    }
  }

  // 以上所有中低层错误都没有处理，而是直接选择上抛，最后交给顶层统一处理
  ```

## 创建 log 日志

- 创建日期文件，并写入错误信息

  - 1.创建时间的时区问题(toISOString)，可以自己改也可以 toLocaleString

  ```js
  const fs = require("fs");
  const path = require("path");

  /**
   * 日志文件：
   *  1.记录日期快捷方法 new Date.toLocaleString(): 用于将日期时间转换为 “本地化字符串”，格式会根据运行环境的语言和地区设置自动调整
   *  2.日期格式 toISOString的返回的是UTC 时区的标准时间字符串， 中国是UTC+8
   * （格式：YYYY-MM-DDTHH:mm:ss.sssZ），例如 2024-10-17T07:35:20.123Z（Z 表示 UTC 时区）， 时区不同会造成，北京时间同一天的不同时间在utc时区被划分为2天
   *  解决方法是，手写一个new Date获取北京时间， 或者调用toLocaleString的api
   *
   * 3.path.join / path.resolve 前者可以处理相对路径，后者不行
   */

  // --------------------------
  // 1. 模拟数据源（包含正常数据和错误数据）
  // --------------------------
  const userDataList = [
    { id: "u001", name: "张三", level: 1 }, // 正常：普通用户
    { id: "u002", name: "李四", level: 2 }, // 正常：会员
    { name: "王五", level: 3 }, // 错误：缺少id
    { id: "u004", name: "赵六", level: "admin" }, // 错误：level类型错误（应为数字）
    { id: "u005", name: "钱七" }, // 错误：缺少level字段
    { id: "u006", name: "孙八", level: 3 }, // 正常：管理员
  ];

  // --------------------------
  // 2. 日志记录工具函数
  // --------------------------
  /**
   * 记录错误日志
   * @param {string} errorMsg 错误信息
   * @param {string|number} dataId 错误数据的id（无id则用索引）
   */
  function logError(errorMsg, dataId) {
    const logDir = path.join(__dirname, "error-logs");
    // 确保日志目录存在
    if (!fs.existsSync(logDir)) {
      fs.mkdirSync(logDir, { recursive: true });
    }
    // 日志内容（包含时间、数据标识、错误信息）
    const logContent = `[${new Date().toLocaleString()}] 数据ID: ${dataId} 错误: ${errorMsg}\n`;
    // 追加到日志文件（每天一个日志文件）格式: 年月日T时分秒
    const logFileName = `error-${new Date().toISOString().split("T")[0]}.txt`;
    const logPath = path.join(logDir, logFileName);
    fs.appendFileSync(logPath, logContent, "utf8");
    console.log(`❌ 已记录错误日志（数据ID: ${dataId}）`);
  }

  // --------------------------
  // 3. 数据处理函数（可能报错）
  // --------------------------
  /**
   * 对单条用户数据进行分类
   * @param {Object} user 单条用户数据
   * @returns {Object} 分类结果
   * @throws {Error} 数据格式错误时抛出异常
   */
  function classifyUser(user) {
    // 校验数据格式（缺少必要字段则报错）
    if (!user.id) {
      throw new Error("缺少id字段");
    }
    if (user.level === undefined) {
      throw new Error("缺少level字段");
    }
    if (typeof user.level !== "number") {
      throw new Error(`level应为数字，实际为${typeof user.level}`);
    }

    // 正常分类逻辑
    let category;
    if (user.level === 1) {
      category = "普通用户";
    } else if (user.level === 2) {
      category = "会员用户";
    } else if (user.level === 3) {
      category = "管理员";
    } else {
      category = "未知等级";
    }

    return {
      id: user.id,
      name: user.name,
      category: category,
    };
  }

  // --------------------------
  // 4. 主流程：遍历数据，处理并捕获错误
  // --------------------------
  function processAllUsers() {
    const result = []; // 存储处理成功的结果

    userDataList.forEach((user, index) => {
      try {
        // 尝试处理当前数据
        const classified = classifyUser(user);
        result.push(classified);
        console.log(
          `✅ 处理成功：${user.id || "无ID"} - ${classified.category}`
        );
      } catch (err) {
        // 捕获错误：记录日志（用id或索引标识数据）
        const dataId = user.id || `索引${index}`; // 无id则用数组索引
        logError(err.message, dataId);
        // 不做其他处理，直接进入下一次循环（跳过当前数据）
      }
    });

    console.log("\n===== 处理完成 =====");
    console.log("成功处理的数据：", result);
    console.log("错误日志已保存到：", path.join(__dirname, "error-logs"));
  }

  // 启动处理
  processAllUsers();
  ```

- 手动处理年月日如下

  ```js
  /**
   * 手动处理年月日
   * @returns String 文件名 年月日格式
   */
  function DateFormat() {
    const date = new Date();
    const year = date.getFullYear();
    const month = String(date.getMonth() + 1).padStart(0, 2);
    const day = String(date.getMonth()).padStart(0, 2);
    return `${year}-${month}-${day}`;
  }

  const today = DateFormat();
  console.log(today);
  ```

## 重复数据合并

- 利用 find 和 reduce 进行数据合并

  ```js
  // 筛选问题
  const orderList = [
    {
      orderId: "OD20240501001",
      goods: ["衬衫", "裤子"],
      status: "待付款",
    },
    {
      orderId: "OD20240501002",
      goods: ["运动鞋"],
      status: "已发货",
    },
    {
      orderId: "OD20240501001", // 重复orderId
      goods: ["袜子"], // 新增商品
      status: "已付款", // 状态更新
    },
    {
      orderId: "OD20240501003",
      goods: ["背包"],
      status: "待发货",
    },
  ];

  // acc是已经存入数据的临时表
  const finalOrderList = orderList.reduce((acc, item) => {
    // 如果重复会返回acc的重复item
    const existInfo = acc.find((info) => info.orderId === item.orderId);
    if (existInfo) {
      // 完善重复数据的信息
      existInfo.goods = [...existInfo.goods, ...item.goods];
      existInfo.status = item.status;
    } else {
      acc.push(item);
    }
    return acc;
  }, []); // 初始值为空

  console.log(finalOrderList);
  ```

## 大数据优化查询（可拓）

- ==大体量数据查询==:
  - ==$expr内部的操作运算符: 形如$size 这种需要计算的==，如果针对大体量数据查询，会在每个符合条件的数据中进行运算，比如下面的数据$messages 是一个数组，那么在进行查询比较时，会对每条数据的 messages 数组长度进行获取，然后进行比对，==这是很耗时的==
  ```js
    "query": {
      "createdAt": {
          "$gte": "2025-01-01T16:00:00.000Z",
          "$lte": "2025-10-20T16:00:00.000Z"
      },
      "$expr": {
          "$gt": [
              {
                  "$size": "$messages"
              },
              1
          ]
      }
    }
  ```
  - 补充情景： 聚合函数中使用`$`unwind 拆分数组的操作，20 万条数据
    - 耗时的核心不是 $unwind 本身，而是以下两个关键问题：
      - 数据膨胀效应：如果每条文档的数组字段有 N 个元素，$unwind 后会生成「20 万 × N」条文档（比如 N=10，就变成 200 万条），后续聚合阶段（$group $sort）需要处理的数据量暴增；
      - 缺少索引支持：如果 $match 阶段没有筛选条件（或筛选条件无索引），会对全集合拆分数组，相当于 “遍历 20 万条文档 + 拆分 200 万条数据”
- ==总结核心：**重要的：合理的索引 + $match 操作缩小要拆分的范围， 这里共性是 mongodb 无法对整体数组进行操作，所以 size 是获取了数组的长度，这个需要对每条数据进行操作，而拆分 unwind 则是为了计算数组内某些数据进行必要的操作，而拆分就会导致数据变多，所以也会耗时**==

- 大数据（500 万）的查询缓慢问题

  - 1.regex 匹配正则表达式，模糊匹配，忽略大小写，可能会导致索引失效 -> 全表, 原始的 title（有大小写的情况下）， 会按照正常 unicode 方式排序
    xxxx

  ```js
  db.Topappdata.createIndex(
    { title: 1 },
    { collation: { locale: "en", strength: 2 } }
  );
  ```

  - 2.$group 直接开始分组，没任何的匹配，所以默认全部查，挨个进行分组 -> 全表 -> 没有全表查询， u 已经配置了 match
  - 可能，i/o 磁盘速度远慢于内存操作

## 分片执行（待）

- ==把数组按照一定数量分片，返回分片后的数组==
  ```js
  function arrayChunks(arr, size) {
    let chunks = [];
    for (let i = 0; i < arr.length; i += size) {
      let chunk = arr.slice(i, i + size);
      chunks.push(chunk);
    }
    return chunks;
  }
  ```
- 数据格式大致为 (10 为一组)
  ```
    chunks = [
      [item1, item2, ..... , item10],
      [item11, item12, ..... , item20],
      [item21, item22, ..... , item30],
      ......
    ]
  ```
  > 通过 chunks[x]获取每一组的数据

## nodemon-ignore

- 有时用 nodemon 执行运行文件时，它会默认扫描项目文件是否变化，当项目文件变化的时候会重新执行，这是它的特性，但是如果代码中涉及文件创建和删除等操作时也会被误认为项目文件发生变化，从而重复执行陷入循环
- ==解决： 项目根目录下配置 nodemon.json 文件，在内部配置忽略的文件地址 ignore==
  ```json
  {
    "ignore": ["testData/addphotosByChunk/**/*"]
  }
  ```

## 重定向下载图片（待）

- 在网络上直接下载图片，可能有重定向问题的下载方法
